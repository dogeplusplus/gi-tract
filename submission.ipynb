{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Submission File","metadata":{}},{"cell_type":"markdown","source":"# Install Libraries","metadata":{}},{"cell_type":"code","source":"!rm -rf /kaggle/working/requirements\n!cp -r -x ../input/gi-tract-models/packages/requirements /kaggle/working\n\n!tar -czf /kaggle/working/requirements/efficientnet_pytorch-0.6.3.tar.gz -C /kaggle/working/requirements/efficientnet_pytorch-0.6.3/efficientnet_pytorch-0.6.3 .\n!rm -rf /kaggle/working/requirements/efficientnet_pytorch-0.6.3\n\n!tar -czf /kaggle/working/requirements/pretrainedmodels-0.7.4.tar.gz -C /kaggle/working/requirements/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4 .\n!rm -rf /kaggle/working/requirements/pretrainedmodels-0.7.4","metadata":{"execution":{"iopub.status.busy":"2022-05-28T16:28:23.74602Z","iopub.execute_input":"2022-05-28T16:28:23.746363Z","iopub.status.idle":"2022-05-28T16:28:34.369398Z","shell.execute_reply.started":"2022-05-28T16:28:23.746279Z","shell.execute_reply":"2022-05-28T16:28:34.368669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --no-index --find-links=/kaggle/working/requirements segmentation-models-pytorch\n!pip install --no-index --find-links=/kaggle/working/requirements einops","metadata":{"execution":{"iopub.status.busy":"2022-05-28T16:28:34.370752Z","iopub.execute_input":"2022-05-28T16:28:34.371031Z","iopub.status.idle":"2022-05-28T16:29:03.304611Z","shell.execute_reply.started":"2022-05-28T16:28:34.371001Z","shell.execute_reply":"2022-05-28T16:29:03.303881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nimport cv2\nimport time\nimport torch\nimport torch.nn as nn\nimport logging\nimport numpy as np\nimport pandas as pd\nimport albumentations as A\n\nfrom pathlib import Path\nfrom tqdm.notebook import tqdm\nfrom einops import repeat, rearrange\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-05-28T16:29:03.307621Z","iopub.execute_input":"2022-05-28T16:29:03.307994Z","iopub.status.idle":"2022-05-28T16:29:07.704373Z","shell.execute_reply.started":"2022-05-28T16:29:03.30792Z","shell.execute_reply":"2022-05-28T16:29:07.703146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tqdm.pandas()\nlogger = logging.getLogger(__name__)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T16:29:07.706647Z","iopub.execute_input":"2022-05-28T16:29:07.706934Z","iopub.status.idle":"2022-05-28T16:29:07.711876Z","shell.execute_reply.started":"2022-05-28T16:29:07.7069Z","shell.execute_reply":"2022-05-28T16:29:07.710535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# IO","metadata":{}},{"cell_type":"code","source":"def load_image(image_path: Path) -> torch.Tensor:\n    img = cv2.imread(str(image_path), cv2.IMREAD_UNCHANGED)\n    img = repeat(img, \"h w -> h w c\", c=3)\n    img = np.asarray(img, np.float32)\n    mx = np.max(img)\n    if mx:\n        img /= mx\n    \n    return img","metadata":{"execution":{"iopub.status.busy":"2022-05-28T16:51:13.756462Z","iopub.execute_input":"2022-05-28T16:51:13.756802Z","iopub.status.idle":"2022-05-28T16:51:13.763514Z","shell.execute_reply.started":"2022-05-28T16:51:13.756764Z","shell.execute_reply":"2022-05-28T16:51:13.762633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SubmissionDataSet(Dataset):\n    def __init__(self, image_paths, transforms=None):\n        self.image_paths = image_paths\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.image_paths)\n        \n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        slice_number = img_path.stem[:10]\n        case_day = img_path.parent.parent.name\n        index = f\"{case_day}_{slice_number}\"\n        \n        image = load_image(img_path)\n        height, width, chans = image.shape\n        if self.transforms:\n            data = self.transforms(image=image)\n            image = data[\"image\"]\n\n        return image, index, height, width","metadata":{"execution":{"iopub.status.busy":"2022-05-28T16:29:07.727608Z","iopub.execute_input":"2022-05-28T16:29:07.728023Z","iopub.status.idle":"2022-05-28T16:29:07.736982Z","shell.execute_reply.started":"2022-05-28T16:29:07.727982Z","shell.execute_reply":"2022-05-28T16:29:07.736414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_metadata(row):\n    data = row['id'].split('_')\n    case = int(data[0].replace('case',''))\n    day = int(data[1].replace('day',''))\n    slice_ = int(data[-1])\n    row['case'] = case\n    row['day'] = day\n    row['slice'] = slice_\n    return row\n\ndef path2info(row):\n    path = row['image_path']\n    data = path.split('/')\n    slice_ = int(data[-1].split('_')[1])\n    case = int(data[-3].split('_')[0].replace('case',''))\n    day = int(data[-3].split('_')[1].replace('day',''))\n    width = int(data[-1].split('_')[2])\n    height = int(data[-1].split('_')[3])\n    row['height'] = height\n    row['width'] = width\n    row['case'] = case\n    row['day'] = day\n    row['slice'] = slice_\n    return row","metadata":{"execution":{"iopub.status.busy":"2022-05-28T16:29:07.738354Z","iopub.execute_input":"2022-05-28T16:29:07.738588Z","iopub.status.idle":"2022-05-28T16:29:07.751799Z","shell.execute_reply.started":"2022-05-28T16:29:07.738555Z","shell.execute_reply":"2022-05-28T16:29:07.751073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv')\nif not len(sub_df):\n    debug = True\n    sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')[:1000*3]\n    sub_df = sub_df.drop(columns=['class','segmentation']).drop_duplicates()   \nelse:\n    debug = False\n    sub_df = sub_df.drop(columns=['class','predicted']).drop_duplicates()\nsub_df = sub_df.progress_apply(get_metadata, axis=1)\n\nlogger.info(f\"Sub df length: {len(sub_df)}\")\nprint(len(sub_df))\nsub_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-28T16:29:07.753017Z","iopub.execute_input":"2022-05-28T16:29:07.753257Z","iopub.status.idle":"2022-05-28T16:29:10.054066Z","shell.execute_reply.started":"2022-05-28T16:29:07.75323Z","shell.execute_reply":"2022-05-28T16:29:10.053148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from glob import glob \n\nif debug:\n    paths = glob(f'/kaggle/input/uw-madison-gi-tract-image-segmentation/train/**/*png',recursive=True)\n#     paths = sorted(paths)\nelse:\n    paths = glob(f'/kaggle/input/uw-madison-gi-tract-image-segmentation/test/**/*png',recursive=True)\n    \npath_df = pd.DataFrame(paths, columns=['image_path'])\npath_df = path_df.progress_apply(path2info, axis=1)\n\nlogger.info(f\"Path df length: {len(path_df)}\")\nprint(len(path_df))\npath_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-28T16:29:10.055363Z","iopub.execute_input":"2022-05-28T16:29:10.055585Z","iopub.status.idle":"2022-05-28T16:30:41.718022Z","shell.execute_reply.started":"2022-05-28T16:29:10.055556Z","shell.execute_reply":"2022-05-28T16:30:41.71708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = sub_df.merge(path_df, on=['case','day','slice'], how='left')\n\nlogger.info(f\"Test df length: {len(test_df)}\")\nprint(len(test_df))\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-28T16:30:41.720941Z","iopub.execute_input":"2022-05-28T16:30:41.721202Z","iopub.status.idle":"2022-05-28T16:30:41.75846Z","shell.execute_reply.started":"2022-05-28T16:30:41.721172Z","shell.execute_reply":"2022-05-28T16:30:41.75793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_paths = [Path(x) for x in test_df[\"image_path\"].tolist()]\nassert len(image_paths) > 0, \"Could not find any images\"\n\nINPUT_SIZE = (224, 224)\ntransforms = A.Compose([\n    A.Resize(*INPUT_SIZE, cv2.INTER_NEAREST)\n])\n\ntest_ds = SubmissionDataSet(image_paths, transforms)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T16:30:41.7595Z","iopub.execute_input":"2022-05-28T16:30:41.759678Z","iopub.status.idle":"2022-05-28T16:30:41.775932Z","shell.execute_reply.started":"2022-05-28T16:30:41.759648Z","shell.execute_reply":"2022-05-28T16:30:41.774978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 20\ntest_loader = DataLoader(\n    test_ds,\n    batch_size=batch_size,\n    num_workers=4,\n    pin_memory=True,\n    drop_last=False\n)\n\nlogger.info(\"Loaded dataset...\")","metadata":{"execution":{"iopub.status.busy":"2022-05-28T16:30:41.777538Z","iopub.execute_input":"2022-05-28T16:30:41.777826Z","iopub.status.idle":"2022-05-28T16:30:41.786655Z","shell.execute_reply.started":"2022-05-28T16:30:41.777766Z","shell.execute_reply":"2022-05-28T16:30:41.785961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def running_length(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\n\n\ndef convert_to_rle(mask: np.ndarray, id: str) -> pd.DataFrame:\n    rows = []\n    channel_index = {\n        \"large_bowel\": 0,\n        \"small_bowel\": 1,\n        \"stomach\": 2,\n    }\n\n    for name, index in channel_index.items():\n        submask = mask[..., index]\n        # ordered from top to bottom, left to right\n        flat_mask = submask.flatten()\n        predicted = running_length(flat_mask)\n        entry = {\n            \"id\": id,\n            \"class\": name,\n            \"predicted\": predicted or None,\n        }\n        rows.append(entry)\n\n    df = pd.DataFrame(rows)\n    return df\n\n\ndef batch_rle_encoding(masks, indices, heights, widths):\n    rles = []\n    for mask, index, height, width in zip(masks, indices, heights, widths):\n        # (width, height) for opencv\n        mask_resized = cv2.resize(mask, (width, height), cv2.INTER_NEAREST)\n        rle = convert_to_rle(mask_resized, index)\n        rles.append(rle)\n        \n    return rles","metadata":{"execution":{"iopub.status.busy":"2022-05-28T16:51:18.581119Z","iopub.execute_input":"2022-05-28T16:51:18.58234Z","iopub.status.idle":"2022-05-28T16:51:18.595794Z","shell.execute_reply.started":"2022-05-28T16:51:18.582271Z","shell.execute_reply":"2022-05-28T16:51:18.595149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"import gc\n\nthr = 0.5\n\nframes = []\n\nimage_samples = []\nmask_samples = []\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n@torch.no_grad()\ndef inference(data_loader, model_paths):\n    for idx, (images, indices, heights, widths) in enumerate(tqdm(data_loader)):\n        images = rearrange(images, \"b h w c -> b c h w\")\n        images = images.to(device)\n        \n        cumulative = torch.zeros_like(images)\n        for mp in model_paths:\n            model = torch.load(mp, map_location=device)\n            pred = model(images)\n            probs = nn.Sigmoid()(pred)\n            cumulative += probs\n            \n        probabilities = cumulative / len(model_paths)\n\n        masks = (probabilities > thr).detach().cpu().numpy()\n        masks = masks.astype(np.uint8)\n        masks = rearrange(masks, \"b c h w -> b h w c\")\n\n        if debug and idx % 10 == 0:\n            image_samples.append(rearrange(images.detach().cpu().numpy(), \"b c h w -> b h w c\"))\n            mask_samples.append(masks)\n\n\n        heights = heights.detach().cpu().numpy()\n        widths = widths.detach().cpu().numpy()\n\n        rle = batch_rle_encoding(masks, indices, heights, widths)\n        frames.extend(rle)\n        logger.info(f\"Completed step: {(idx + 1) * batch_size}\")\n        \n        del images, masks\n        gc.collect()\n        torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-05-28T16:51:19.202082Z","iopub.execute_input":"2022-05-28T16:51:19.203009Z","iopub.status.idle":"2022-05-28T16:51:19.217991Z","shell.execute_reply.started":"2022-05-28T16:51:19.202962Z","shell.execute_reply":"2022-05-28T16:51:19.21714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"version = 3\n\nmodel_dir = Path(\"/kaggle\", \"input\", \"gi-tract-models\", str(version))\nmodel_paths = list(model_dir.iterdir())\nlogger.info(f\"Model Loaded {str(version)}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-28T16:51:19.841172Z","iopub.execute_input":"2022-05-28T16:51:19.841499Z","iopub.status.idle":"2022-05-28T16:51:19.848535Z","shell.execute_reply.started":"2022-05-28T16:51:19.841461Z","shell.execute_reply":"2022-05-28T16:51:19.847868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time.time()\ninference(test_loader, model_paths)\nend = time.time()\n\nlogger.info(f\"Total time taken to perform inference: {end - start}s\")","metadata":{"execution":{"iopub.status.busy":"2022-05-28T16:51:20.368039Z","iopub.execute_input":"2022-05-28T16:51:20.368334Z","iopub.status.idle":"2022-05-28T16:53:31.305149Z","shell.execute_reply.started":"2022-05-28T16:51:20.368305Z","shell.execute_reply":"2022-05-28T16:53:31.303972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission File","metadata":{}},{"cell_type":"code","source":"sub = pd.concat(frames).reset_index(drop=True)\nsub.columns = [\"id\", \"class\", \"predicted\"]\nsub.to_csv(\"submission.csv\", index=False)\nlogger.info(\"Saved submission...\")\nsub","metadata":{"execution":{"iopub.status.busy":"2022-05-28T16:51:06.215218Z","iopub.status.idle":"2022-05-28T16:51:06.215558Z","shell.execute_reply.started":"2022-05-28T16:51:06.215372Z","shell.execute_reply":"2022-05-28T16:51:06.21539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -r /kaggle/working/requirements","metadata":{"execution":{"iopub.status.busy":"2022-05-28T16:40:24.568505Z","iopub.execute_input":"2022-05-28T16:40:24.568774Z","iopub.status.idle":"2022-05-28T16:40:24.998874Z","shell.execute_reply.started":"2022-05-28T16:40:24.56874Z","shell.execute_reply":"2022-05-28T16:40:24.997801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(sub))\nprint(len(sub[~sub[\"predicted\"].isna()]))\nsub[~sub[\"predicted\"].isna()]","metadata":{"execution":{"iopub.status.busy":"2022-05-28T16:50:20.285062Z","iopub.execute_input":"2022-05-28T16:50:20.285492Z","iopub.status.idle":"2022-05-28T16:50:20.29816Z","shell.execute_reply.started":"2022-05-28T16:50:20.28545Z","shell.execute_reply":"2022-05-28T16:50:20.297058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction Visualisation","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nif len(image_samples) > 0:\n    idx = np.random.randint(0, len(image_samples))\n\n    image_batch = image_samples[idx]\n    mask_batch = mask_samples[idx]\n\n    for i in range(image_batch.shape[0]):\n        fig, ax = plt.subplots(1, 2)\n        ax[0].imshow(image_batch[i])\n        ax[1].imshow(mask_batch[i] * 255)\n        ax[0].axis('off')\n        ax[1].axis('off')\n        plt.tight_layout()\n        plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-28T16:40:25.016003Z","iopub.execute_input":"2022-05-28T16:40:25.016311Z","iopub.status.idle":"2022-05-28T16:40:25.378745Z","shell.execute_reply.started":"2022-05-28T16:40:25.016275Z","shell.execute_reply":"2022-05-28T16:40:25.377753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
