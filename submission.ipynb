{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Submission File","metadata":{}},{"cell_type":"markdown","source":"# Install Libraries","metadata":{}},{"cell_type":"code","source":"!rm -rf /kaggle/working/requirements\n!cp -r -x ../input/gi-tract-models/packages/requirements /kaggle/working\n\n!tar -czf /kaggle/working/requirements/efficientnet_pytorch-0.6.3.tar.gz -C /kaggle/working/requirements/efficientnet_pytorch-0.6.3/efficientnet_pytorch-0.6.3 .\n!rm -rf /kaggle/working/requirements/efficientnet_pytorch-0.6.3\n\n!tar -czf /kaggle/working/requirements/pretrainedmodels-0.7.4.tar.gz -C /kaggle/working/requirements/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4 .\n!rm -rf /kaggle/working/requirements/pretrainedmodels-0.7.4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --no-index --find-links=/kaggle/working/requirements segmentation-models-pytorch\n!pip install --no-index --find-links=/kaggle/working/requirements einops","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nimport cv2\nimport time\nimport torch\nimport torch.nn as nn\nimport logging\nimport numpy as np\nimport pandas as pd\nimport albumentations as A\n\nfrom pathlib import Path\nfrom tqdm.notebook import tqdm\nfrom einops import repeat, rearrange\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm import tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tqdm.pandas()\nlogger = logging.getLogger(__name__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# IO","metadata":{}},{"cell_type":"code","source":"def load_image(image_path: Path) -> torch.Tensor:\n    img = cv2.imread(str(image_path), cv2.IMREAD_UNCHANGED)\n    img = repeat(img, \"h w -> h w c\", c=3)\n    img = np.asarray(img, np.float32)\n    img /= img.max()\n    \n    return img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SubmissionDataSet(Dataset):\n    def __init__(self, image_paths, transforms=None):\n        self.image_paths = image_paths\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.image_paths)\n        \n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        slice_number = img_path.stem[:10]\n        case_day = img_path.parent.parent.name\n        index = f\"{case_day}_{slice_number}\"\n        \n        image = load_image(img_path)\n        height, width, chans = image.shape\n        if self.transforms:\n            data = self.transforms(image=image)\n            image = data[\"image\"]\n\n        return image, index, height, width","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_metadata(row):\n    data = row['id'].split('_')\n    case = int(data[0].replace('case',''))\n    day = int(data[1].replace('day',''))\n    slice_ = int(data[-1])\n    row['case'] = case\n    row['day'] = day\n    row['slice'] = slice_\n    return row\n\ndef path2info(row):\n    path = row['image_path']\n    data = path.split('/')\n    slice_ = int(data[-1].split('_')[1])\n    case = int(data[-3].split('_')[0].replace('case',''))\n    day = int(data[-3].split('_')[1].replace('day',''))\n    width = int(data[-1].split('_')[2])\n    height = int(data[-1].split('_')[3])\n    row['height'] = height\n    row['width'] = width\n    row['case'] = case\n    row['day'] = day\n    row['slice'] = slice_\n    return row","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv')\nif not len(sub_df):\n    debug = True\n    sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')[:1000*3]\n    sub_df = sub_df.drop(columns=['class','segmentation']).drop_duplicates()   \nelse:\n    debug = False\n    sub_df = sub_df.drop(columns=['class','predicted']).drop_duplicates()\nsub_df = sub_df.progress_apply(get_metadata, axis=1)\n\nlogger.info(f\"Sub df length: {len(sub_df)}\")\nprint(len(sub_df))\nsub_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from glob import glob \n\nif debug:\n    paths = glob(f'/kaggle/input/uw-madison-gi-tract-image-segmentation/train/**/*png',recursive=True)\n#     paths = sorted(paths)\nelse:\n    paths = glob(f'/kaggle/input/uw-madison-gi-tract-image-segmentation/test/**/*png',recursive=True)\n    \npath_df = pd.DataFrame(paths, columns=['image_path'])\npath_df = path_df.progress_apply(path2info, axis=1)\n\nlogger.info(f\"Path df length: {len(path_df)}\")\nprint(len(path_df))\npath_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = sub_df.merge(path_df, on=['case','day','slice'], how='left')\n\nlogger.info(f\"Test df length: {len(test_df)}\")\nprint(len(test_df))\ntest_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_paths = [Path(x) for x in test_df[\"image_path\"].tolist()]\nassert len(image_paths) > 0, \"Could not find any images\"\n\nINPUT_SIZE = (224, 224)\ntransforms = A.Compose([\n    A.Resize(*INPUT_SIZE, cv2.INTER_NEAREST)\n])\n\ntest_ds = SubmissionDataSet(image_paths, transforms)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 20\ntest_loader = DataLoader(\n    test_ds,\n    batch_size=batch_size,\n    num_workers=4,\n    pin_memory=True,\n    drop_last=False\n)\n\nlogger.info(\"Loaded dataset...\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def running_length(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\n\n\ndef convert_to_rle(mask: np.ndarray, id: str) -> pd.DataFrame:\n    rows = []\n    channel_index = {\n        \"large_bowel\": 0,\n        \"small_bowel\": 1,\n        \"stomach\": 2,\n    }\n\n    for name, index in channel_index.items():\n        submask = mask[..., index]\n        # ordered from top to bottom, left to right\n        flat_mask = submask.flatten()\n        predicted = running_length(flat_mask)\n        entry = {\n            \"id\": id,\n            \"class\": name,\n            \"predicted\": predicted or None,\n        }\n        rows.append(entry)\n\n    df = pd.DataFrame(rows)\n    return df\n\n\ndef batch_rle_encoding(masks, indices, heights, widths):\n    rles = []\n    for mask, index, height, width in zip(masks, indices, heights, widths):\n        mask_resized = cv2.resize(mask, (height, width), cv2.INTER_NEAREST)\n        rle = convert_to_rle(mask_resized, index)\n        rles.append(rle)\n        \n    return rles","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"import gc\n\nthr = 0.5\n\nframes = []\n\nimage_samples = []\nmask_samples = []\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n@torch.no_grad()\ndef inference(data_loader, model_paths):\n    for idx, (images, indices, heights, widths) in enumerate(tqdm(data_loader)):\n        images = rearrange(images, \"b h w c -> b c h w\")\n        images = images.to(device)\n        \n        cumulative = torch.zeros_like(images)\n        \n        for mp in model_paths:\n            model = torch.load(mp, map_location=device)\n            pred = model(images)\n            probs = nn.Sigmoid()(pred)\n            cumulative += probs\n            \n        probabilities = cumulative / len(model_paths)\n\n        masks = (probabilities > thr).detach().cpu().numpy()\n        masks = masks.astype(np.uint8)\n        masks = rearrange(masks, \"b c h w -> b h w c\")\n\n        if debug:\n            image_samples.append(rearrange(images.detach().cpu().numpy(), \"b c h w -> b h w c\"))\n            mask_samples.append(masks)\n\n\n        heights = heights.detach().cpu().numpy()\n        widths = widths.detach().cpu().numpy()\n\n        rle = batch_rle_encoding(masks, indices, heights, widths)\n        frames.extend(rle)\n        logger.info(f\"Completed step: {(idx + 1) * batch_size}\")\n        \n        del images, masks\n        gc.collect()\n        torch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"version = 2\n\nmodel_dir = Path(\"/kaggle\", \"input\", \"gi-tract-models\", str(version))\nmodel_paths = list(model_dir.iterdir())\nlogger.info(f\"Model Loaded {str(version)}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time.time()\ninference(test_loader, model_paths)\nend = time.time()\n\nlogger.info(f\"Total time taken to perform inference: {end - start}s\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission File","metadata":{}},{"cell_type":"code","source":"sub = pd.concat(frames).reset_index(drop=True)\nsub.columns = [\"id\", \"class\", \"predicted\"]\nsub.to_csv(\"submission.csv\", index=False)\nlogger.info(\"Saved submission...\")\nsub","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -r /kaggle/working/requirements","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(sub))\nprint(len(sub[~sub[\"predicted\"].isna()]))\nsub[~sub[\"predicted\"].isna()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction Visualisation","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nif len(image_samples) > 0:\n    idx = np.random.randint(0, len(image_samples))\n\n    image_batch = image_samples[idx]\n    mask_batch = mask_samples[idx]\n\n    for i in range(image_batch.shape[0]):\n        fig, ax = plt.subplots(1, 2)\n        ax[0].imshow(image_batch[i])\n        ax[1].imshow(mask_batch[i] * 255)\n        ax[0].axis('off')\n        ax[1].axis('off')\n        plt.tight_layout()\n        plt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}
