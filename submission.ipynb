{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Submission File","metadata":{}},{"cell_type":"markdown","source":"# Install Libraries","metadata":{}},{"cell_type":"code","source":"!rm -rf /kaggle/working/requirements\n!cp -r -x ../input/gi-tract-models/packages/requirements /kaggle/working\n# !tar -czf /kaggle/working/requirements/cupy-10.4.0.tar.gz -C /kaggle/working/requirements/cupy-10.4.0/cupy-10.4.0 .\n# !rm -rf /kaggle/working/requirements/cupy-10.4.0\n\n!tar -czf /kaggle/working/requirements/efficientnet_pytorch-0.6.3.tar.gz -C /kaggle/working/requirements/efficientnet_pytorch-0.6.3/efficientnet_pytorch-0.6.3 .\n!rm -rf /kaggle/working/requirements/efficientnet_pytorch-0.6.3\n\n!tar -czf /kaggle/working/requirements/pretrainedmodels-0.7.4.tar.gz -C /kaggle/working/requirements/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4 .\n!rm -rf /kaggle/working/requirements/pretrainedmodels-0.7.4","metadata":{"execution":{"iopub.status.busy":"2022-05-22T10:57:31.084753Z","iopub.execute_input":"2022-05-22T10:57:31.085743Z","iopub.status.idle":"2022-05-22T10:57:40.575884Z","shell.execute_reply.started":"2022-05-22T10:57:31.085697Z","shell.execute_reply":"2022-05-22T10:57:40.574765Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"!pip install --no-index --find-links=/kaggle/working/requirements segmentation-models-pytorch\n!pip install --no-index --find-links=/kaggle/working/requirements einops","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:04:37.158931Z","iopub.execute_input":"2022-05-22T11:04:37.159241Z","iopub.status.idle":"2022-05-22T11:04:52.493933Z","shell.execute_reply.started":"2022-05-22T11:04:37.159207Z","shell.execute_reply":"2022-05-22T11:04:52.492940Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import sys\nimport cv2\nimport time\nimport torch\nimport logging\nimport numpy as np\nimport pandas as pd\nimport albumentations as A\n\nfrom pathlib import Path\nfrom tqdm.notebook import tqdm\nfrom einops import repeat, rearrange\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:08:30.282957Z","iopub.execute_input":"2022-05-22T11:08:30.283276Z","iopub.status.idle":"2022-05-22T11:08:30.296599Z","shell.execute_reply.started":"2022-05-22T11:08:30.283238Z","shell.execute_reply":"2022-05-22T11:08:30.295562Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"tqdm.pandas()\nlogger = logging.getLogger(__name__)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:08:31.938009Z","iopub.execute_input":"2022-05-22T11:08:31.938340Z","iopub.status.idle":"2022-05-22T11:08:31.944743Z","shell.execute_reply.started":"2022-05-22T11:08:31.938302Z","shell.execute_reply":"2022-05-22T11:08:31.943646Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# IO","metadata":{}},{"cell_type":"code","source":"def load_image(image_path: Path) -> torch.Tensor:\n    img = cv2.imread(str(image_path), cv2.IMREAD_UNCHANGED)\n    img = np.asarray(img, np.float32)\n    img /= img.max()\n    \n    return img","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:08:32.649428Z","iopub.execute_input":"2022-05-22T11:08:32.649821Z","iopub.status.idle":"2022-05-22T11:08:32.655956Z","shell.execute_reply.started":"2022-05-22T11:08:32.649782Z","shell.execute_reply":"2022-05-22T11:08:32.655201Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"# Load Pre-Trained Model","metadata":{}},{"cell_type":"code","source":"version = \"v0\"\nlogged_model = f\"../input/gi-tract-models/{version}.pth\"\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = torch.load(logged_model, map_location=device)\nmodel = model.to(device)\nmodel.eval()\n\nlogger.info(f\"Model Loaded {version}\")","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-05-22T11:08:33.288321Z","iopub.execute_input":"2022-05-22T11:08:33.288637Z","iopub.status.idle":"2022-05-22T11:08:42.198263Z","shell.execute_reply.started":"2022-05-22T11:08:33.288606Z","shell.execute_reply":"2022-05-22T11:08:42.197177Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"class SubmissionDataSet(Dataset):\n    def __init__(self, image_paths, transforms=None):\n        self.image_paths = image_paths\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.image_paths)\n        \n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        slice_number = img_path.stem[:10]\n        case_day = img_path.parent.parent.name\n        index = f\"{case_day}_{slice_number}\"\n        \n        image = load_image(img_path)\n        height, width = image.shape\n        if self.transforms:\n            data = self.transforms(image=image)\n            image = data[\"image\"]\n\n        return image, index, height, width","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:08:42.200698Z","iopub.execute_input":"2022-05-22T11:08:42.201298Z","iopub.status.idle":"2022-05-22T11:08:42.210215Z","shell.execute_reply.started":"2022-05-22T11:08:42.201229Z","shell.execute_reply":"2022-05-22T11:08:42.209382Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def get_metadata(row):\n    data = row['id'].split('_')\n    case = int(data[0].replace('case',''))\n    day = int(data[1].replace('day',''))\n    slice_ = int(data[-1])\n    row['case'] = case\n    row['day'] = day\n    row['slice'] = slice_\n    return row\n\ndef path2info(row):\n    path = row['image_path']\n    data = path.split('/')\n    slice_ = int(data[-1].split('_')[1])\n    case = int(data[-3].split('_')[0].replace('case',''))\n    day = int(data[-3].split('_')[1].replace('day',''))\n    width = int(data[-1].split('_')[2])\n    height = int(data[-1].split('_')[3])\n    row['height'] = height\n    row['width'] = width\n    row['case'] = case\n    row['day'] = day\n    row['slice'] = slice_\n    return row","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:08:42.228285Z","iopub.execute_input":"2022-05-22T11:08:42.228538Z","iopub.status.idle":"2022-05-22T11:08:42.239909Z","shell.execute_reply.started":"2022-05-22T11:08:42.228509Z","shell.execute_reply":"2022-05-22T11:08:42.238812Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv')\nif not len(sub_df):\n    debug = True\n    sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')[:1000*3]\n    sub_df = sub_df.drop(columns=['class','segmentation']).drop_duplicates()   \nelse:\n    debug = False\n    sub_df = sub_df.drop(columns=['class','predicted']).drop_duplicates()\nsub_df = sub_df.progress_apply(get_metadata, axis=1)\n\nlogger.info(f\"Sub df length: {len(sub_df)}\")\nprint(len(sub_df))\nsub_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:08:42.241502Z","iopub.execute_input":"2022-05-22T11:08:42.242004Z","iopub.status.idle":"2022-05-22T11:08:44.290682Z","shell.execute_reply.started":"2022-05-22T11:08:42.241973Z","shell.execute_reply":"2022-05-22T11:08:44.289798Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"from glob import glob \n\nif debug:\n    paths = glob(f'/kaggle/input/uw-madison-gi-tract-image-segmentation/train/**/*png',recursive=True)\n#     paths = sorted(paths)\nelse:\n    paths = glob(f'/kaggle/input/uw-madison-gi-tract-image-segmentation/test/**/*png',recursive=True)\n    \npath_df = pd.DataFrame(paths, columns=['image_path'])\npath_df = path_df.progress_apply(path2info, axis=1)\n\nlogger.info(f\"Path df length: {len(path_df)}\")\nprint(len(path_df))\npath_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:08:44.292143Z","iopub.execute_input":"2022-05-22T11:08:44.292366Z","iopub.status.idle":"2022-05-22T11:10:32.222588Z","shell.execute_reply.started":"2022-05-22T11:08:44.292339Z","shell.execute_reply":"2022-05-22T11:10:32.221467Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"test_df = sub_df.merge(path_df, on=['case','day','slice'], how='left')\n\nlogger.info(f\"Test df length: {len(test_df)}\")\nprint(len(test_df))\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:10:32.224275Z","iopub.execute_input":"2022-05-22T11:10:32.224791Z","iopub.status.idle":"2022-05-22T11:10:32.265358Z","shell.execute_reply.started":"2022-05-22T11:10:32.224747Z","shell.execute_reply":"2022-05-22T11:10:32.264444Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"image_paths = [Path(x) for x in test_df[\"image_path\"].tolist()]\nassert len(image_paths) > 0, \"Could not find any images\"\n\nINPUT_SIZE = (224, 224)\ntransforms = A.Compose([\n    A.Resize(*INPUT_SIZE, cv2.INTER_NEAREST)\n])\n\ntest_ds = SubmissionDataSet(image_paths, transforms)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:10:32.266954Z","iopub.execute_input":"2022-05-22T11:10:32.267223Z","iopub.status.idle":"2022-05-22T11:10:32.285541Z","shell.execute_reply.started":"2022-05-22T11:10:32.267175Z","shell.execute_reply":"2022-05-22T11:10:32.284277Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"batch_size = 20\ntest_loader = DataLoader(\n    test_ds,\n    batch_size=batch_size,\n    num_workers=4,\n    pin_memory=True,\n    drop_last=False\n)\n\nlogger.info(\"Loaded dataset...\")","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:10:32.287581Z","iopub.execute_input":"2022-05-22T11:10:32.287869Z","iopub.status.idle":"2022-05-22T11:10:32.295836Z","shell.execute_reply.started":"2022-05-22T11:10:32.287824Z","shell.execute_reply":"2022-05-22T11:10:32.294963Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def running_length(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\n\n\ndef convert_to_rle(mask: np.ndarray, id: str) -> pd.DataFrame:\n    rows = []\n    channel_index = {\n        \"large_bowel\": 0,\n        \"small_bowel\": 1,\n        \"stomach\": 2,\n    }\n\n    for name, index in channel_index.items():\n        submask = mask[..., index]\n        # ordered from top to bottom, left to right\n        flat_mask = submask.flatten(order=\"F\")\n        predicted = running_length(flat_mask)\n        entry = {\n            \"id\": id,\n            \"class\": name,\n            \"predicted\": predicted or None,\n        }\n        rows.append(entry)\n\n    df = pd.DataFrame(rows)\n    return df\n\n\ndef batch_rle_encoding(masks, indices, heights, widths):\n    rles = []\n    for mask, index, height, width in zip(masks, indices, heights, widths):\n        mask_resized = cv2.resize(mask, (height, width), cv2.INTER_NEAREST)\n        rle = convert_to_rle(mask_resized, index)\n        rles.append(rle)\n        \n    return rles","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:21:58.354965Z","iopub.execute_input":"2022-05-22T11:21:58.355314Z","iopub.status.idle":"2022-05-22T11:21:58.368364Z","shell.execute_reply.started":"2022-05-22T11:21:58.355274Z","shell.execute_reply":"2022-05-22T11:21:58.367413Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"thr = 0.5\nstart = time.time()\nframes = []\n\nfor idx, (images, indices, heights, widths) in enumerate(tqdm(test_loader)):\n    images = repeat(images, \"b h w -> b c h w\", c=3)\n    images = images.to(device)\n    probs = model(images)\n    \n    masks = (probs > thr).detach().cpu().numpy()\n    masks = masks.astype(np.uint8)\n    masks = rearrange(masks, \"b c h w -> b h w c\")\n    \n    heights = heights.detach().cpu().numpy()\n    widths = widths.detach().cpu().numpy()\n\n    rle = batch_rle_encoding(masks, indices, heights, widths)\n    frames.extend(rle)\n    logger.info(f\"Completed step: {(idx + 1) * batch_size}\")\n    \nend = time.time()\nlogger.info(f\"Total time taken to perform inference: {end - start}s\")","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:22:05.183662Z","iopub.execute_input":"2022-05-22T11:22:05.184111Z","iopub.status.idle":"2022-05-22T11:23:56.765026Z","shell.execute_reply.started":"2022-05-22T11:22:05.184078Z","shell.execute_reply":"2022-05-22T11:23:56.763068Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"sub = pd.concat(frames).reset_index(drop=True)\nsub.columns = [\"id\", \"class\", \"predicted\"]\nsub.to_csv(\"submission.csv\", index=False)\nlogger.info(\"Saved submission...\")\nsub","metadata":{"execution":{"iopub.status.busy":"2022-05-22T11:24:00.261611Z","iopub.execute_input":"2022-05-22T11:24:00.262168Z","iopub.status.idle":"2022-05-22T11:24:00.413312Z","shell.execute_reply.started":"2022-05-22T11:24:00.262116Z","shell.execute_reply":"2022-05-22T11:24:00.412719Z"},"trusted":true},"execution_count":54,"outputs":[]}]}
